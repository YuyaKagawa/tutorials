{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考: https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このチュートリアルではPyTorchの動かし方を学びます。  \n",
    "PyTorchは2種類の特徴を持っています。  \n",
    "<ul>\n",
    "    <li>n次元のテンソルをGPUで動かせる</li>\n",
    "    <li>ニューラルネットワークの構築と学習においての自動微分</li>\n",
    "</ul>\n",
    "このチュートリアルでは全結合のReluのネットワークを使います。ネットワークには隠れ層が1層あり、勾配降下法で最適化します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずnumpyでネットワークを実装してみます。numpyはn次元のarrayのオブジェクトを使えます。numpyは数値計算にむいていますが、計算グラフやディープラーニングや勾配についての情報は持っていません。ただ2層くらいだったらnumpyでforwardとbackward込みで実装できます。  \n",
    "まずはネットワークの構築です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T07:58:41.351187Z",
     "start_time": "2020-04-21T07:58:41.332961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  (64, 1000)\n",
      "y =  (64, 10)\n",
      "w1 =  (1000, 100)\n",
      "w2 =  (100, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Nはバッチサイズ、D_inは入力の次元\n",
    "# Hは隠れ層の次元、D_outは出力の次元\n",
    "N,D_in,H,D_out=64,1000,100,10\n",
    "\n",
    "# ランダムな入力と出力のデータを生成\n",
    "x=np.random.randn(N,D_in) # (1000,)がバッチサイズ64個分\n",
    "y=np.random.randn(N,D_out) # (10,)がバッチサイズ64個分\n",
    "\n",
    "print(\"x = \",x.shape)\n",
    "print(\"y = \",y.shape)\n",
    "\n",
    "# 重みをランダムな値で初期化\n",
    "w1=np.random.randn(D_in,H) # 1000→100\n",
    "w2=np.random.randn(H,D_out) # 100→10\n",
    "\n",
    "print(\"w1 = \",w1.shape)\n",
    "print(\"w2 = \",w2.shape)\n",
    "\n",
    "learning_rate=1e-6 # 学習率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは学習させてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T07:58:44.006098Z",
     "start_time": "2020-04-21T07:58:43.221282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31823478.64102552\n",
      "1 28664697.11072056\n",
      "2 27177728.48114389\n",
      "3 23924352.459111504\n",
      "4 18297027.783265993\n",
      "5 12159365.726656396\n",
      "6 7319922.7658959\n",
      "7 4307388.4810226895\n",
      "8 2638349.768839662\n",
      "9 1748376.3967286015\n",
      "10 1257545.3302723526\n",
      "11 966869.5974510428\n",
      "12 778260.087715298\n",
      "13 645084.5712176858\n",
      "14 544727.1464991323\n",
      "15 465621.2507244223\n",
      "16 401278.25149095536\n",
      "17 347966.75784856256\n",
      "18 303181.20164392306\n",
      "19 265222.39391120384\n",
      "20 232861.95343195298\n",
      "21 205128.15383292665\n",
      "22 181235.53536597226\n",
      "23 160603.4135914872\n",
      "24 142715.2989601657\n",
      "25 127152.7975961942\n",
      "26 113540.56395353696\n",
      "27 101598.84457884528\n",
      "28 91136.02799754421\n",
      "29 81935.94878479112\n",
      "30 73807.56925874762\n",
      "31 66607.91961471579\n",
      "32 60210.479892593095\n",
      "33 54519.51930362925\n",
      "34 49446.732255665\n",
      "35 44917.74604277941\n",
      "36 40863.89808077119\n",
      "37 37224.12215310537\n",
      "38 33950.73040594339\n",
      "39 31004.115138373185\n",
      "40 28348.85167781714\n",
      "41 25950.341422123693\n",
      "42 23779.9464973942\n",
      "43 21815.09999841234\n",
      "44 20032.8234273912\n",
      "45 18415.178626433957\n",
      "46 16944.791090433137\n",
      "47 15607.042785114427\n",
      "48 14387.716199769759\n",
      "49 13274.989533930397\n",
      "50 12258.231046532128\n",
      "51 11328.34141893704\n",
      "52 10476.502002056008\n",
      "53 9696.197516277816\n",
      "54 8980.675071580277\n",
      "55 8323.287640397411\n",
      "56 7719.266045269347\n",
      "57 7163.604896947871\n",
      "58 6652.459796925578\n",
      "59 6181.249181798534\n",
      "60 5746.6885519496245\n",
      "61 5345.957194890872\n",
      "62 4976.06204886602\n",
      "63 4634.007960266046\n",
      "64 4317.776054786109\n",
      "65 4025.3277528259387\n",
      "66 3754.454557890407\n",
      "67 3503.485351689331\n",
      "68 3270.9152108349026\n",
      "69 3055.1242643477754\n",
      "70 2854.83808465301\n",
      "71 2668.821587058716\n",
      "72 2495.919994684036\n",
      "73 2335.2239991299302\n",
      "74 2185.7409939120444\n",
      "75 2046.678403512928\n",
      "76 1917.1994044190185\n",
      "77 1796.4742489289033\n",
      "78 1683.9646574656676\n",
      "79 1579.0256553787365\n",
      "80 1481.145296630069\n",
      "81 1389.8249362038366\n",
      "82 1304.542876749231\n",
      "83 1224.8593196081986\n",
      "84 1150.3922817963326\n",
      "85 1080.9755437418307\n",
      "86 1016.5111931576881\n",
      "87 956.1951997267586\n",
      "88 899.7514654624606\n",
      "89 846.907706586389\n",
      "90 797.381371140088\n",
      "91 750.9420420267777\n",
      "92 707.4050640130095\n",
      "93 666.5609300353165\n",
      "94 628.2462912549613\n",
      "95 592.2986158970676\n",
      "96 558.5311229281326\n",
      "97 526.8138421872658\n",
      "98 496.93344809439054\n",
      "99 468.8562591764664\n",
      "100 442.4634018118324\n",
      "101 417.6738909452898\n",
      "102 394.34352579289947\n",
      "103 372.38869085805237\n",
      "104 351.7260466008423\n",
      "105 332.27762868266734\n",
      "106 313.968817549783\n",
      "107 296.7257322768585\n",
      "108 280.4818836924517\n",
      "109 265.178493079287\n",
      "110 250.75461861498871\n",
      "111 237.1549844286113\n",
      "112 224.33414693655516\n",
      "113 212.25210745959308\n",
      "114 200.84296944778612\n",
      "115 190.08011183359145\n",
      "116 179.9231442680003\n",
      "117 170.33744510731333\n",
      "118 161.2848504732116\n",
      "119 152.78231111008034\n",
      "120 144.80533423490945\n",
      "121 137.26913578166509\n",
      "122 130.14756228864294\n",
      "123 123.41701841177368\n",
      "124 117.05465212178377\n",
      "125 111.04442667301119\n",
      "126 105.35164813056792\n",
      "127 99.96541351975607\n",
      "128 94.8686918147317\n",
      "129 90.0457408710825\n",
      "130 85.48056082095394\n",
      "131 81.1570116082317\n",
      "132 77.0624035529418\n",
      "133 73.18365265182426\n",
      "134 69.5090963791695\n",
      "135 66.02699582654267\n",
      "136 62.727628824921766\n",
      "137 59.60371675202115\n",
      "138 56.6385420467258\n",
      "139 53.82772096613377\n",
      "140 51.16185947478815\n",
      "141 48.63342679471735\n",
      "142 46.23465819327384\n",
      "143 43.959213839218954\n",
      "144 41.79988582994066\n",
      "145 39.750863210990545\n",
      "146 37.806056631672504\n",
      "147 35.96048961320875\n",
      "148 34.20943829398662\n",
      "149 32.5467444346493\n",
      "150 30.96651969001693\n",
      "151 29.465834718663373\n",
      "152 28.04021986918447\n",
      "153 26.68604235093076\n",
      "154 25.39955525938287\n",
      "155 24.177324826559413\n",
      "156 23.016015379016633\n",
      "157 21.91210657177482\n",
      "158 20.862934351629875\n",
      "159 19.865589065561018\n",
      "160 18.91850241772063\n",
      "161 18.01730647665842\n",
      "162 17.16010706658492\n",
      "163 16.34493609070995\n",
      "164 15.569895615193623\n",
      "165 14.832494768412124\n",
      "166 14.131018110767107\n",
      "167 13.463797230274828\n",
      "168 12.828945878799434\n",
      "169 12.224956003131467\n",
      "170 11.650128446030395\n",
      "171 11.103370033810208\n",
      "172 10.58341189240224\n",
      "173 10.087879088300264\n",
      "174 9.616175666535765\n",
      "175 9.167083482407842\n",
      "176 8.739568050459782\n",
      "177 8.332539865750928\n",
      "178 7.944986394536282\n",
      "179 7.575891626713323\n",
      "180 7.224346291660934\n",
      "181 6.889596083592993\n",
      "182 6.570686163192109\n",
      "183 6.267143016414259\n",
      "184 5.978030779805721\n",
      "185 5.702363017580616\n",
      "186 5.43967859813207\n",
      "187 5.189408000793272\n",
      "188 4.950885288353417\n",
      "189 4.723603457093102\n",
      "190 4.507040897121183\n",
      "191 4.300599738522287\n",
      "192 4.103824295047692\n",
      "193 3.9162506625499933\n",
      "194 3.7374436175156283\n",
      "195 3.567189795455101\n",
      "196 3.4047147366646726\n",
      "197 3.24976272541873\n",
      "198 3.1019989875895444\n",
      "199 2.9611170696365354\n",
      "200 2.8267628148214516\n",
      "201 2.6986203913730256\n",
      "202 2.576419948456768\n",
      "203 2.4598586659737776\n",
      "204 2.3486790080238134\n",
      "205 2.242619827794872\n",
      "206 2.141475380258439\n",
      "207 2.0450878660405265\n",
      "208 1.9530192172374716\n",
      "209 1.865155717206771\n",
      "210 1.7813195255813685\n",
      "211 1.7013257131548092\n",
      "212 1.6249922781075405\n",
      "213 1.5521519356298175\n",
      "214 1.482643990995337\n",
      "215 1.4163012541740545\n",
      "216 1.3529788517987016\n",
      "217 1.2925380255809396\n",
      "218 1.234870040878117\n",
      "219 1.1798599465518465\n",
      "220 1.1272820737400737\n",
      "221 1.0770901425886306\n",
      "222 1.0291703393189815\n",
      "223 0.9834204406089089\n",
      "224 0.9397441301717597\n",
      "225 0.8980380948734596\n",
      "226 0.8582099559540413\n",
      "227 0.820178714395948\n",
      "228 0.7838625209826363\n",
      "229 0.7491816446598292\n",
      "230 0.7160768470890208\n",
      "231 0.6844644433092684\n",
      "232 0.6542437641519305\n",
      "233 0.6253810818833179\n",
      "234 0.5978195592559428\n",
      "235 0.5714849073957959\n",
      "236 0.5463254790420597\n",
      "237 0.5222907273082393\n",
      "238 0.4993285020119895\n",
      "239 0.4773979551541599\n",
      "240 0.45643974466028714\n",
      "241 0.4364149521817456\n",
      "242 0.41729410841900805\n",
      "243 0.39902475875543414\n",
      "244 0.3815578156590772\n",
      "245 0.3648625078435862\n",
      "246 0.34890700994640284\n",
      "247 0.33366092771852973\n",
      "248 0.31909003606034697\n",
      "249 0.3051654018430889\n",
      "250 0.29185514271377266\n",
      "251 0.2791330177319617\n",
      "252 0.26697329448508644\n",
      "253 0.2553521426917607\n",
      "254 0.24424989127709792\n",
      "255 0.23363574022724046\n",
      "256 0.2234824010587934\n",
      "257 0.21377514431830957\n",
      "258 0.20449682238257638\n",
      "259 0.19562618872967633\n",
      "260 0.18714386688718973\n",
      "261 0.179034492523577\n",
      "262 0.17128105571436164\n",
      "263 0.16386826686438827\n",
      "264 0.15677881708844787\n",
      "265 0.1500002815976009\n",
      "266 0.1435208580328926\n",
      "267 0.1373280445170404\n",
      "268 0.13140038135673646\n",
      "269 0.12573057602625937\n",
      "270 0.1203087654242399\n",
      "271 0.11512388903664603\n",
      "272 0.11016553575636183\n",
      "273 0.10542209830488568\n",
      "274 0.10088518156894216\n",
      "275 0.09654559328824949\n",
      "276 0.092395520449364\n",
      "277 0.08842567792931671\n",
      "278 0.08462828800125624\n",
      "279 0.08099944701747694\n",
      "280 0.07752398783359553\n",
      "281 0.07419962707237046\n",
      "282 0.07101893050499761\n",
      "283 0.06797597843342632\n",
      "284 0.06506467458956874\n",
      "285 0.06227983872349463\n",
      "286 0.05961506942042462\n",
      "287 0.057065254309158465\n",
      "288 0.054625867652815296\n",
      "289 0.05229192147254162\n",
      "290 0.050058701722220655\n",
      "291 0.04792328397601986\n",
      "292 0.04587885107147239\n",
      "293 0.0439217084477569\n",
      "294 0.042049494782220656\n",
      "295 0.04025730749437671\n",
      "296 0.03854218027450956\n",
      "297 0.036900895008684535\n",
      "298 0.03533036015804543\n",
      "299 0.033827125454019044\n",
      "300 0.032388436406576716\n",
      "301 0.03101140945292205\n",
      "302 0.02969354760195294\n",
      "303 0.028432716065106025\n",
      "304 0.027226261010303163\n",
      "305 0.026070523245430542\n",
      "306 0.024964405025353287\n",
      "307 0.02390572457080504\n",
      "308 0.022892075354837248\n",
      "309 0.021921806175091586\n",
      "310 0.02099298568453033\n",
      "311 0.020104086059537438\n",
      "312 0.01925295052307619\n",
      "313 0.01843811395725457\n",
      "314 0.01765801394567106\n",
      "315 0.016911402054176683\n",
      "316 0.016197024251403885\n",
      "317 0.015512733036130457\n",
      "318 0.014857373568528759\n",
      "319 0.014230006246914173\n",
      "320 0.013629259831615743\n",
      "321 0.013054059647963722\n",
      "322 0.012503321549011332\n",
      "323 0.011976036405326016\n",
      "324 0.011471195098814044\n",
      "325 0.010987704514886384\n",
      "326 0.010524735542023954\n",
      "327 0.010081489919690455\n",
      "328 0.009657082641410443\n",
      "329 0.009250981365016252\n",
      "330 0.008861701231251238\n",
      "331 0.00848894311808087\n",
      "332 0.00813200761853673\n",
      "333 0.007790138301148802\n",
      "334 0.007462735335546762\n",
      "335 0.00714919675666764\n",
      "336 0.006848975230924882\n",
      "337 0.006561387013409859\n",
      "338 0.006285953122604953\n",
      "339 0.0060221575039471915\n",
      "340 0.00576957655290996\n",
      "341 0.005527618685290172\n",
      "342 0.0052960580899011\n",
      "343 0.005074073372526371\n",
      "344 0.0048614934991107524\n",
      "345 0.00465781954587832\n",
      "346 0.004462745071161565\n",
      "347 0.0042758846203153535\n",
      "348 0.004096940860272938\n",
      "349 0.003925501984076425\n",
      "350 0.00376126682936847\n",
      "351 0.0036039470138931337\n",
      "352 0.0034532923943042066\n",
      "353 0.0033089336417703764\n",
      "354 0.003170650943349071\n",
      "355 0.0030383005315036725\n",
      "356 0.0029114176610331383\n",
      "357 0.0027898311285885083\n",
      "358 0.0026733568014572612\n",
      "359 0.0025617774122319906\n",
      "360 0.002454902976789487\n",
      "361 0.0023524836621444285\n",
      "362 0.002254364434785592\n",
      "363 0.0021603577714397436\n",
      "364 0.002070321948739257\n",
      "365 0.0019840358234854364\n",
      "366 0.0019013596786307389\n",
      "367 0.0018221470007297519\n",
      "368 0.0017463346708036843\n",
      "369 0.0016736332050497403\n",
      "370 0.0016039581818244521\n",
      "371 0.0015372004077185905\n",
      "372 0.0014732502818258675\n",
      "373 0.0014119573246976253\n",
      "374 0.001353230841757429\n",
      "375 0.0012969607051648842\n",
      "376 0.0012430518518014994\n",
      "377 0.0011913831016073053\n",
      "378 0.001141873045264981\n",
      "379 0.0010944291751780614\n",
      "380 0.0010489807238917449\n",
      "381 0.0010054441907226847\n",
      "382 0.0009637058220073997\n",
      "383 0.0009236976527835041\n",
      "384 0.0008853706444544064\n",
      "385 0.0008486309035887925\n",
      "386 0.0008134232454778563\n",
      "387 0.0007796833186364982\n",
      "388 0.0007473562071961702\n",
      "389 0.0007163670227129697\n",
      "390 0.0006866706453462221\n",
      "391 0.0006582110348422798\n",
      "392 0.0006309417103379053\n",
      "393 0.0006048005574282424\n",
      "394 0.0005797564039086759\n",
      "395 0.0005557583191268085\n",
      "396 0.0005327506623667527\n",
      "397 0.0005106956044542856\n",
      "398 0.0004895557639652155\n",
      "399 0.00046929537816398515\n",
      "400 0.00044988250600637593\n",
      "401 0.00043127024353192497\n",
      "402 0.0004134312695167177\n",
      "403 0.00039633516904414207\n",
      "404 0.00037995076571048253\n",
      "405 0.0003642429865900259\n",
      "406 0.0003491874501365248\n",
      "407 0.00033475741909993236\n",
      "408 0.0003209382773176855\n",
      "409 0.0003076803192560664\n",
      "410 0.00029497163113491895\n",
      "411 0.00028279028756229266\n",
      "412 0.00027111520334006136\n",
      "413 0.00025992246674591893\n",
      "414 0.0002491929667803784\n",
      "415 0.00023890914688039412\n",
      "416 0.00022905237341819447\n",
      "417 0.00021960172454487208\n",
      "418 0.0002105423823240631\n",
      "419 0.0002018596311292933\n",
      "420 0.0001935364371202792\n",
      "421 0.000185558652757756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422 0.00017791215546851644\n",
      "423 0.00017057970294253686\n",
      "424 0.00016355009253114577\n",
      "425 0.00015681044280968742\n",
      "426 0.00015034972495256603\n",
      "427 0.00014415684471490303\n",
      "428 0.00013821939868532274\n",
      "429 0.000132527100842352\n",
      "430 0.00012707004372643\n",
      "431 0.00012183928619211875\n",
      "432 0.00011682387750872615\n",
      "433 0.000112015340018149\n",
      "434 0.00010740523782888872\n",
      "435 0.00010298880814873531\n",
      "436 9.875297022913718e-05\n",
      "437 9.46904208894794e-05\n",
      "438 9.079554355535838e-05\n",
      "439 8.706245705206053e-05\n",
      "440 8.348241313541856e-05\n",
      "441 8.004993038630952e-05\n",
      "442 7.675917432104123e-05\n",
      "443 7.360473398808896e-05\n",
      "444 7.057953722367017e-05\n",
      "445 6.767921202484466e-05\n",
      "446 6.489861859383496e-05\n",
      "447 6.223284537937133e-05\n",
      "448 5.967634664272143e-05\n",
      "449 5.722659601674396e-05\n",
      "450 5.4877028625524724e-05\n",
      "451 5.2624016823283655e-05\n",
      "452 5.046339940095749e-05\n",
      "453 4.839171410330933e-05\n",
      "454 4.64054991852871e-05\n",
      "455 4.450121263856558e-05\n",
      "456 4.2675006136275984e-05\n",
      "457 4.0923894829429454e-05\n",
      "458 3.924503559527972e-05\n",
      "459 3.763530237422944e-05\n",
      "460 3.609153767037097e-05\n",
      "461 3.461125664378606e-05\n",
      "462 3.31921472609937e-05\n",
      "463 3.18319484496436e-05\n",
      "464 3.0526991000304535e-05\n",
      "465 2.9275536577726878e-05\n",
      "466 2.8075758596408226e-05\n",
      "467 2.6925088591247874e-05\n",
      "468 2.5821611100474544e-05\n",
      "469 2.476353625337173e-05\n",
      "470 2.3749137382990183e-05\n",
      "471 2.2776157929177155e-05\n",
      "472 2.1843175458735093e-05\n",
      "473 2.0948484578281672e-05\n",
      "474 2.0090713843045593e-05\n",
      "475 1.9267979092697112e-05\n",
      "476 1.847901544509635e-05\n",
      "477 1.77228081504281e-05\n",
      "478 1.699754568301427e-05\n",
      "479 1.6301772144839155e-05\n",
      "480 1.5634527840092977e-05\n",
      "481 1.4994686752909647e-05\n",
      "482 1.438120087057718e-05\n",
      "483 1.379274502547661e-05\n",
      "484 1.3228410547415789e-05\n",
      "485 1.2687289296036629e-05\n",
      "486 1.216838956462086e-05\n",
      "487 1.167066594038726e-05\n",
      "488 1.1193345022892214e-05\n",
      "489 1.0735663846614569e-05\n",
      "490 1.0296732326977188e-05\n",
      "491 9.875838150137884e-06\n",
      "492 9.47222751016886e-06\n",
      "493 9.085073025285827e-06\n",
      "494 8.71374389121269e-06\n",
      "495 8.357593920779463e-06\n",
      "496 8.016038444420521e-06\n",
      "497 7.688522168441884e-06\n",
      "498 7.374379244595774e-06\n",
      "499 7.073085963553903e-06\n"
     ]
    }
   ],
   "source": [
    "# 500エポック\n",
    "for t in range(500):\n",
    "    # forward: yの予測値を計算\n",
    "    h=x.dot(w1) # h=w1*x\n",
    "    h_relu=np.maximum(h,0) # h_relu=relu(h)\n",
    "    y_pred=h_relu.dot(w2) # y_pred=w2*h_relu\n",
    "    \n",
    "    # ロスを計算して表示\n",
    "    loss=np.square(y_pred-y).sum() # 二乗誤差を計算\n",
    "    print(t,loss)\n",
    "    \n",
    "    # ロスをw1とw2の勾配を計算するために逆伝搬\n",
    "    grad_y_pred=2.0*(y_pred-y)\n",
    "    grad_w2=h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu=grad_y_pred.dot(w2.T)\n",
    "    grad_h=grad_h_relu.copy()\n",
    "    grad_h[h<0]=0\n",
    "    grad_w1=x.T.dot(grad_h)\n",
    "    \n",
    "    # 重みを更新\n",
    "    w1-=learning_rate*grad_w1 # w1=w1-lr*w1'\n",
    "    w2-=learning_rate*grad_w2 # w2=w2-lr*w2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpyは素晴らしいフレームワークですが、GPUの恩恵を受けられません。GPUを使うと50倍も早くなったりするので、是非使いたいです。  \n",
    "PyTorchの根幹をなすのがテンソルです。PyTorchのテンソルはnumpyのarrayと同じです。テンソルはn次元のarrayで、PyTorchはこれを操作する関数があります。  \n",
    "テンソルは計算グラフと勾配を見ることができます。またGPUも使えます。GPUでPyTorchを使いたい場合は、新しいデータのタイプに変換する必要があります。  \n",
    "ここではPyTorchのテンソルで2層のネットワークを学習させます。numpyのときと同様に、forwardとbackwardのパスを実装する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:32:45.646944Z",
     "start_time": "2020-04-22T02:32:45.290289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 914.9981689453125\n",
      "199 14.325092315673828\n",
      "299 0.40440312027931213\n",
      "399 0.01374082826077938\n",
      "499 0.000772079627495259\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype=torch.float # データの型はfloat\n",
    "device=torch.device(\"cpu\") # CPUで実行\n",
    "# device=torch.device(\"cuda:0\") # GPUで実行\n",
    "\n",
    "# Nはバッチサイズ、D_inは入力の次元\n",
    "# Hは隠れ層の次元、D_outは出力の次元\n",
    "N,D_in,H,D_out=64,1000,100,10\n",
    "\n",
    "# ランダムな入力と出力のデータを生成する\n",
    "x=torch.randn(N,D_in,device=device,dtype=dtype)\n",
    "y=torch.randn(N,D_out,device=device,dtype=dtype)\n",
    "\n",
    "# 重みをランダムに初期化\n",
    "w1=torch.randn(D_in,H,device=device,dtype=dtype)\n",
    "w2=torch.randn(H,D_out,device=device,dtype=dtype)\n",
    "\n",
    "learning_rate=1e-6 # 学習率\n",
    "\n",
    "for t in range(500): # 500エポック回す\n",
    "    # forward: yの予測値を計算\n",
    "    h=x.mm(w1) # h=w1*x\n",
    "    h_relu=h.clamp(min=0) # h_relu=relu(h)\n",
    "    y_pred=h_relu.mm(w2) # y_pred=w2*h_relu\n",
    "    \n",
    "    # ロスを計算して表示\n",
    "    loss=(y_pred-y).pow(2).sum().item() # SE\n",
    "    \n",
    "    if t%100==99: # 100エポックごとに表示\n",
    "        print(t,loss)\n",
    "        \n",
    "    # w1とw2の勾配を計算して逆伝搬\n",
    "    grad_y_pred=2.0*(y_pred-y)\n",
    "    grad_w2=h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu=grad_y_pred.mm(w2.t())\n",
    "    grad_h=grad_h_relu.clone()\n",
    "    grad_h[h<0]=0\n",
    "    grad_w1=x.t().mm(grad_h)\n",
    "    \n",
    "    # 勾配降下法で重みを更新\n",
    "    w1-=learning_rate*grad_w1\n",
    "    w2-=learning_rate*grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまでの例では、ニューラルネットワークの順伝搬・逆伝搬ともに自分で実装しなければなりませんでした。ネットワークが大きくなると自力でやるのは辛いです。  \n",
    "ありがたいことに、ニューラルネットワークには自動微分の仕組みがあります。PyTorchではautogradのパッケージが使えます。autogradを使うと、forwardで計算グラフを定義します。各ノードはテンソルで、各エッジは入力のテンソルから出力のテンソルを作る関数となります。このグラフを作れば逆伝搬で簡単に勾配を計算できます。  \n",
    "xをテンソルとしたとき、x.requires_grad=Trueとするとx.gradがxの勾配を持つことになります。  \n",
    "それではPyTorchのテンソルとautogradを使って2層のネットワークを構成します。autogradを利用すると、backwardを実装する必要がなくなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T11:13:44.042086Z",
     "start_time": "2020-04-22T11:13:43.605711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 567.8706665039062\n",
      "199 2.621206045150757\n",
      "299 0.018998155370354652\n",
      "399 0.0003641570801846683\n",
      "499 5.5538352171424776e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype=torch.float # データ型はfloat\n",
    "device=torch.device(\"cpu\") # CPUの場合\n",
    "# device=torch.device(\"cuda:0\") # GPUの場合\n",
    "\n",
    "# 入力と出力を持つランダムなテンソルを生成する\n",
    "# requires_grad=Falseとすると、backwardで勾配を計算しないということになる\n",
    "# 入力、出力なので勾配を持つ必要はない\n",
    "x=torch.randn(N,D_in,device=device,dtype=dtype,requires_grad=False)\n",
    "y=torch.randn(N,D_out,device=device,dtype=dtype,requires_grad=False)\n",
    "\n",
    "# ランダムな値を持つ重みのテンソルを作成\n",
    "# requires_grad=Trueとすることでbackwardで勾配を計算することとする\n",
    "w1=torch.randn(D_in,H,device=device,dtype=dtype,requires_grad=True)\n",
    "w2=torch.randn(H,D_out,device=device,dtype=dtype,requires_grad=True)\n",
    "\n",
    "learning_rate=1e-6 # 学習率\n",
    "\n",
    "for t in range(500): # エポックで繰り返す\n",
    "    # forwardでは、yの予測値を計算する\n",
    "    # 以前とは違い、逆伝搬のために中間の値を持っておく必要はない\n",
    "    \n",
    "    # (N,D_in)×(D_in,H)→(N,H), (N,H)×(H,D_out)→(N,D_out)\n",
    "    # clamp()は値を範囲内に変更する関数、ここではrelu\n",
    "    y_pred=x.mm(w1).clamp(min=0).mm(w2) \n",
    "    \n",
    "    # ロスを計算して表示する\n",
    "    # ロスは(1,)のテンソルに入っている\n",
    "    # loss.item()でスカラーを取れる\n",
    "    loss=(y_pred-y).pow(2).sum()\n",
    "    \n",
    "    if t%100==99: # 100回ごとに表示\n",
    "        print(t,loss.item())\n",
    "        \n",
    "    # backwardはrequires_grad=Trueとしたおかげで1行ですむ\n",
    "    # requires_grad=Trueとした全てのテンソルについて、ロスの勾配を計算する\n",
    "    # この後にw1.grad,w2.gradでそれぞれ勾配を取得できる\n",
    "    loss.backward()\n",
    "    \n",
    "    # 勾配降下法で重みを更新する\n",
    "    # torch.no_grad()の中で実行することで、勾配の計算に影響を与えないようにする\n",
    "    # weight.dataとweight.grad.dataで実装する方法もある\n",
    "    # tensor.dataはtensorと同じデータを返すが、勾配に影響を与えない\n",
    "    # torch.optimでもできる\n",
    "    with torch.no_grad():\n",
    "        w1-=learning_rate*w1.grad # w1の更新\n",
    "        w2-=learning_rate*w2.grad # w2の更新\n",
    "        \n",
    "        # 重みを更新した後に、手動で勾配をゼロにする\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autogradの関数を自分で定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autogradは操作するのは2つだけです。forward()は入力のテンソルから出力のテンソルを計算します。backward()では出力のテンソルの勾配を受け取って、入力のテンソルの勾配を計算します。  \n",
    "PyTorchではtorch.autograd.Functionのサブクラスを定義してforward()とbackward()を定義することで自作のautogradを定義できます。そして入力となるテンソルを渡してインスタンスを構築して関数として呼ぶことで使用することができます。  \n",
    "ここではReLUの非線形性に対応したautogradを自作し、2層のニューラルネットワークで利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:24:42.899424Z",
     "start_time": "2020-04-22T13:24:42.894522Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    # torch.autograd.Functionをサブクラスとして、forward()とbackward()を実装することで自作のautogradの関数を作ることができる\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx,input):\n",
    "        # forwardでは入力としてテンソルを受け取り、テンソルを出力する\n",
    "        # ctxはbackwardの計算のために情報を保持するcontextのオブジェクト\n",
    "        # ctx.save_for_backward()で任意のオブジェクトを、backwardの計算のために保持できる\n",
    "        ctx.save_for_backward(input)\n",
    "        \n",
    "        return input.clamp(min=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_output):\n",
    "        # backwardではロスの勾配を含むテンソルを受け取る\n",
    "        input,=ctx.saved_tensors\n",
    "        grad_input=grad_output.clone()\n",
    "        grad_input[input<0]=0\n",
    "        \n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それではネットワークを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T13:33:01.423372Z",
     "start_time": "2020-04-22T13:33:00.908406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 425.3764953613281\n",
      "199 1.2911951541900635\n",
      "299 0.005374168511480093\n",
      "399 0.00014156590623315424\n",
      "499 3.016583650605753e-05\n"
     ]
    }
   ],
   "source": [
    "dtype=torch.float\n",
    "device=torch.device(\"cpu\") # CPUで実行\n",
    "# device=torch.device(\"cuda:0\") # GPUで実行\n",
    "\n",
    "# Nはバッチサイズ、D_inは入力の次元\n",
    "# Hは隠れ層の次元、D_outは出力の次元\n",
    "N,D_in,H,D_out=64,1000,100,10\n",
    "\n",
    "# 入力と出力のためにランダムな値を持つテンソルを作る\n",
    "x=torch.randn(N,D_in,device=device,dtype=dtype)\n",
    "y=torch.randn(N,D_out,device=device,dtype=dtype)\n",
    "\n",
    "# 重みのテンソルをランダムな値で初期化\n",
    "w1=torch.randn(D_in,H,device=device,dtype=dtype,requires_grad=True)\n",
    "w2=torch.randn(H,D_out,device=device,dtype=dtype,requires_grad=True)\n",
    "\n",
    "learning_rate=1e-6 # 学習率\n",
    "\n",
    "for t in range(500): # エポック\n",
    "    # 自作の関数を適用するために、Function.applyを使う\n",
    "    relu=MyReLU.apply\n",
    "    \n",
    "    # forward: yの予測値を計算する\n",
    "    # 自作のautogradでReLUを計算する\n",
    "    y_pred=relu(x.mm(w1)).mm(w2)\n",
    "    \n",
    "    # ロスを計算して表示する\n",
    "    loss=(y_pred-y).pow(2).sum() # SE\n",
    "    \n",
    "    if t%100==99: # 100エポックごとに表示\n",
    "        print(t,loss.item())\n",
    "        \n",
    "    # autogradを使ってbackwardを計算する\n",
    "    loss.backward()\n",
    "        \n",
    "    # 勾配降下法で重みを更新する\n",
    "    with torch.no_grad():\n",
    "        w1-=learning_rate*w1.grad\n",
    "        w2-=learning_rate*w2.grad\n",
    "        \n",
    "        # 重みを更新した後に勾配を手動で0にする\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nnモジュール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算グラフとautogradの組み合わせはとても有用ですが、大きいニューラルネットワークに対してはautogradはきついです。  \n",
    "ニューラルネットワークを構築する際は、計算をレイヤに落とし込むことが多いです。このレイヤは学習可能なパラメータも持っています。  \n",
    "TensorFlowでは、Keras、Tensorflow-Slim、TFlLearnといった、生の計算グラフに適用できる上位の概念がありました。  \n",
    "PyTorchでは、上に挙げたものをnnパッケージで実現できます。nnパッケージにはモジュールがあり、これがニューラルネットワークのレイヤに相当します。  \n",
    "モジュールではテンソルを入力とし、同じくテンソルを出力しますが、学習可能なパラメータをもつこともあります。  \n",
    "nnパッケージにはロス関数もあります。  \n",
    "ここでは2層のニューラルネットワークをnnパッケージを使って実装してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:55:55.322813Z",
     "start_time": "2020-04-24T00:55:54.685242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 92.52568054199219\n",
      "199 41.80598068237305\n",
      "299 32.95942306518555\n",
      "399 32.760963439941406\n",
      "499 42.08575439453125\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Nはバッチサイズ、D_inは入力の次元\n",
    "# Hは隠れ層の次元、D_outは出力の次元\n",
    "N,D_in,H,D_out=64,1000,100,10\n",
    "\n",
    "# 入力と出力を持つテンソルを作成し、ランダムな値で初期化する\n",
    "x=torch.randn(N,D_in) # 入力\n",
    "y=torch.randn(N,D_out) # 出力\n",
    "\n",
    "# nnパッケージを使って、モデルをレイヤのシーケンスと捉えて実装する\n",
    "# nn.Sequentialは入力をシーケンスのように処理して出力する\n",
    "# 各Linearモジュールは線形関数を使って入力から出力を計算し、重みとバイアスの内部のテンソルを計算する\n",
    "model=torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in,H), # 線形\n",
    "    torch.nn.ReLU(), # ReLU\n",
    "    torch.nn.Linear(H,D_out) # 線形\n",
    ")\n",
    "\n",
    "# nnパッケージにはロス関数もある\n",
    "# ここではMSEを使う\n",
    "loss_fn=torch.nn.MSELoss(reduction=\"sum\") # MSE\n",
    "\n",
    "learning_rate=1e-4 # 学習率\n",
    "\n",
    "for t in range(500): # エポック\n",
    "    # forward: モデルにxを入力することでyの予測値を計算する\n",
    "    # Moduleオブジェクトは__call__をオーバーライドするので、関数のように呼び出すことができる\n",
    "    # そのときはModuleにテンソルを入れて、出力としてテンソルを得られる\n",
    "    y_pred=model(x) # ネットワークの出力を取得する\n",
    "    \n",
    "    # ロスを計算して表示する\n",
    "    # yの実測値と予測値を入れることで、ロスを取得できる\n",
    "    loss=loss_fn(y_pred,y) # ロス\n",
    "    \n",
    "    if t%100==99: # 100エポックごとに表示\n",
    "        print(t,loss.item())\n",
    "    \n",
    "    # backward: ロスの勾配を学習可能なパラメータについて計算する\n",
    "    # 内部的に、Moduleのパラメータはrequires_grad=Trueとして持っている\n",
    "    # これでモデルの全ての学習可能なパラメータのために勾配を計算できる\n",
    "    loss.backward() # 逆伝搬\n",
    "    \n",
    "    # 勾配降下法で重みを更新する\n",
    "    # 各パラメータはテンソルなので、これまでの方法で各勾配にアクセスできる\n",
    "    with torch.no_grad(): # 勾配を蓄積しない\n",
    "        for param in model.parameters(): # 各パラメータについて\n",
    "            param-=learning_rate*param.grad # パラメータを更新する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまで、重みを手動で更新する方法を見てきました。torch.no_grad()や.dataを使うことで勾配を蓄積せずに進める必要がありました。  \n",
    "最適化関数がSGDとかシンプルなものだったらこれで良いのですが、AdaGrad、RMSProp、Adamなどのもっと複雑なものを使う際にはきついです。  \n",
    "optimパッケージには最適化関数のアルゴリズムのアイデアが取り入れられていて、一般的な最適化関数をカバーしています。  \n",
    "ここでは以前nnパッケージで構築したモデルを、optimパッケージのAdamアルゴリズムで最適化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T03:57:25.447588Z",
     "start_time": "2020-04-24T03:57:24.715222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 39.05604934692383\n",
      "199 0.4798465669155121\n",
      "299 0.0018017084803432226\n",
      "399 3.6764358810614794e-06\n",
      "499 5.767328836725483e-09\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Nはバッチサイズ、D_inは入力の次元\n",
    "# Hは隠れ層の次元、D_outは出力の次元\n",
    "N,D_in,H,D_out=64,1000,100,10\n",
    "\n",
    "# 入力と出力の情報を持つテンソルを作り、ランダムな値で初期化する\n",
    "x=torch.randn(N,D_in) # 入力\n",
    "y=torch.randn(N,D_out) # 出力\n",
    "\n",
    "# nnパッケージを使ってモデルとロス関数を定義する\n",
    "model=torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in,H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H,D_out)\n",
    ")\n",
    "\n",
    "loss_fn=torch.nn.MSELoss(reduction=\"sum\") # ロス関数\n",
    "\n",
    "# optimパッケージで、モデルの重みを最適化する関数を定義する\n",
    "# ここではAdamを使う\n",
    "# optimパッケージにはいろんな最適化関数がある\n",
    "# Adam()の一つ目の引数には更新するテンソルを入れる\n",
    "learning_rate=1e-4 # 学習率\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate) # 最適化関数\n",
    "\n",
    "for t in range(500): # エポック\n",
    "    # forward: モデルにxを入れてyの予測値を計算する\n",
    "    y_pred=model(x) # モデルに入れて出力する\n",
    "    \n",
    "    loss=loss_fn(y_pred,y) # ロス\n",
    "    \n",
    "    if t%100==99: # 100エポックごとにロスを表示する\n",
    "        print(t,loss.item())\n",
    "    \n",
    "    # backward()の前にoptimizer.zero_grad()を実行する\n",
    "    # そうしないと前のエポックで計算した勾配にどんどん蓄積されていってしまう\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # backward: ロスの勾配を計算する\n",
    "    loss.backward()\n",
    "    \n",
    "    # Optimizerのstep()でパラメータの更新を行う\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nnモジュールでクラスを自作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequentialよりも複雑なネットワークを作りたいときは、nn.Moduleをサブクラスにしてforward()を実装します。  \n",
    "このforward()では入力としてテンソルを受け、テンソルを出力とします。  \n",
    "ここでは、下のようにサブクラスを使って2層のネットワークを作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T04:25:08.998601Z",
     "start_time": "2020-04-24T04:25:08.526299Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        # ここではnn.Linearモジュールを2つインスタンス化して、変数として持つ\n",
    "        super(TwoLayerNet,self).__init__()\n",
    "        self.linear1=torch.nn.Linear(D_in,H) # 第1層\n",
    "        self.linear2=torch.nn.Linear(H,D_out) # 第2層\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # forward()ではテンソルを入力として、テンソルを出力する\n",
    "        # __init__()で定義したモジュールも使うことができる\n",
    "        h_relu=self.linear1(x).clamp(min=0) # relu\n",
    "        y_pred=self.linear2(h_relu) # 予測値を算出\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T04:25:08.998601Z",
     "start_time": "2020-04-24T04:25:08.526299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 3.0537233352661133\n",
      "199 0.03936923295259476\n",
      "299 0.0008906815201044083\n",
      "399 3.08222442981787e-05\n",
      "499 1.5793425518495496e-06\n"
     ]
    }
   ],
   "source": [
    "# Nはバッチサイズ、D_inは入力の次元\n",
    "# Hは隠れ層の次元、D_outは出力の次元\n",
    "N,D_in,H,D_out=64,1000,100,10\n",
    "\n",
    "# 入力と出力のテンソル\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "\n",
    "# モデルを構築する\n",
    "model=TwoLayerNet(D_in,H,D_out)\n",
    "\n",
    "# ロス関数と最適化関数を定義する\n",
    "# model.parameters()でモデルの中の学習可能なパラメータを取得できる\n",
    "criterion=torch.nn.MSELoss(reduction=\"sum\")\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1e-4)\n",
    "\n",
    "for t in range(500): # エポック\n",
    "    # forward: モデルでyの予測値を計算する\n",
    "    y_pred=model(x)\n",
    "    \n",
    "    # ロスを計算して表示する\n",
    "    loss=criterion(y_pred,y)\n",
    "    \n",
    "    if t%100==99: # 100エポックごとに表示\n",
    "        print(t,loss.item())\n",
    "        \n",
    "    # 勾配を0にし、逆伝搬させ、重みを更新する\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Flow + Weight Sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動的グラフとweight sharingの例として、変なネットワークを構成します。ここでは、全結合でReLUを使います。  \n",
    "各層では1-4のランダムな値を取得し、その値に応じた回数だけ隠れ層で同じ重みを何度も使いながら再び隠れ層の計算をします。  \n",
    "このモデルではループを構成するのに普通のPythonのflow controlが使えます。  \n",
    "weight sharingはnn.Moduleで実装できます。  \n",
    "こんな感じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T05:06:40.282936Z",
     "start_time": "2020-04-24T05:06:40.267477Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        # ここではforward()で使うnn.Linearのインスタンスを3つ用意する\n",
    "        super(DynamicNet,self).__init__()\n",
    "        self.input_linear=torch.nn.Linear(D_in,H)\n",
    "        self.middle_linear=torch.nn.Linear(H,H)\n",
    "        self.output_linear=torch.nn.Linear(H,D_out)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # 0-3からランダムな整数を取得する\n",
    "        # middle_linearを何回も計算する\n",
    "        # forwardでは動的な計算グラフを構築するので、Pythonのcontrol-flowの枠組みでループを構成する\n",
    "        # 同じModuleを何回も使っても大丈夫\n",
    "        # この点がLua Torchからの改善点\n",
    "        h_relu=self.input_linear(x).clamp(min=0) # relu\n",
    "        \n",
    "        for _ in range(random.randint(0,3)): # 0-3回、さらなる隠れ層の計算をする\n",
    "            h_relu=self.middle_linear(h_relu).clamp(min=0)\n",
    "    \n",
    "        y_pred=self.output_linear(h_relu) # 出力層を計算\n",
    "        \n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは学習させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T05:06:41.957415Z",
     "start_time": "2020-04-24T05:06:41.164005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 21.761653900146484\n",
      "199 6.2540283203125\n",
      "299 1.6713652610778809\n",
      "399 0.5263149738311768\n",
      "499 0.2223612666130066\n"
     ]
    }
   ],
   "source": [
    "# Nはバッチサイズ、D_inは入力の次元\n",
    "# Hは隠れ層の次元、D_outは出力の次元\n",
    "N,D_in,H,D_out=64,1000,100,10\n",
    "\n",
    "# 入力と出力\n",
    "x=torch.randn(N,D_in)\n",
    "y=torch.randn(N,D_out)\n",
    "\n",
    "# モデルを構築\n",
    "model=DynamicNet(D_in,H,D_out)\n",
    "\n",
    "# ロス関数と最適化関数を定義する\n",
    "# このモデルをSGDで学習させるのはきついので、momentumを使う\n",
    "criterion=torch.nn.MSELoss(reduction=\"sum\")\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1e-4,momentum=0.9)\n",
    "\n",
    "for t in range(500):\n",
    "    # forward: yの予測値を計算する\n",
    "    y_pred=model(x)\n",
    "    \n",
    "    # ロスを計算して表示する\n",
    "    loss=criterion(y_pred,y)\n",
    "    \n",
    "    if t%100==99: # 100エポックごとに表示する\n",
    "        print(t,loss.item())\n",
    "        \n",
    "    # 勾配をゼロにし、逆伝搬させて、重みを更新する\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
