{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまで様々なフィードフォワードニューラルネットワークを見てきました。これまでのでは状態を保存する機能はありませんでした。  \n",
    "シーケンスモデルは自然言語処理でよく使われます。これは入力の時系列を考慮できます。  \n",
    "Hiddden Markov Modelとかconditional random fieldとかがよく使われてきました。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNは状態を保存することができるネットワークです。例えば、ある時刻の出力を次の時刻の入力とすることで、情報が時を跨いで伝搬されます。  \n",
    "LSTMでは、シーケンス中の各要素は、隠れ内部状態hというのがあります。これは任意の前の時刻の情報を得られます。  \n",
    "language modelやpart-of-speech tagsやmyriadの場合に内部状態というのが使えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchのLSTMは入力として3次元のテンソルを受け取ります。各軸について把握しておきましょう。  \n",
    "第1軸はシーケンス、第2軸はミニバッチ内のインデックス、そして第3軸は入力の要素です。  \n",
    "まだミニバッチについて言及していないので、ここでは第2軸は1次元とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T04:26:28.654657Z",
     "start_time": "2020-04-27T04:26:28.622769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1131121d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:21:11.933245Z",
     "start_time": "2020-04-27T06:21:11.915127Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm=nn.LSTM(3,3) # 入力の次元は3、出力の次元は3\n",
    "inputs=[torch.randn(1,3) for _ in range(5)] # 長さ5のシーケンスを作る、各シーケンスは(1,3)の形を持つ\n",
    "\n",
    "# 内部状態を初期化する\n",
    "hidden=(torch.randn(1,1,3),torch.randn(1,1,3))\n",
    "\n",
    "# 各入力について\n",
    "for i in inputs:\n",
    "    # シーケンスの各時刻について実行する\n",
    "    # 各ステップの後、hiddenに内部状態が入る\n",
    "    out,hidden=lstm(i.view(1,1,-1),hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代わりに、一度に複数のシーケンスを入れることもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:21:12.841035Z",
     "start_time": "2020-04-27T06:21:12.823531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden before running =  (tensor([[[ 0.0085,  0.0678, -0.2043]]]), tensor([[[-0.5243, -0.3088,  0.4444]]]))\n",
      "out =  tensor([[[-0.0123,  0.0384,  0.3112]],\n",
      "\n",
      "        [[ 0.0533,  0.1213,  0.2932]],\n",
      "\n",
      "        [[ 0.0745,  0.1729,  0.3718]],\n",
      "\n",
      "        [[-0.0109,  0.2084,  0.4683]],\n",
      "\n",
      "        [[-0.0401,  0.2125,  0.4205]]], grad_fn=<StackBackward>)\n",
      "hidden after running =  (tensor([[[-0.0401,  0.2125,  0.4205]]], grad_fn=<StackBackward>), tensor([[[-0.1283,  0.4025,  0.6685]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "# 一つ目の返り値は、シーケンス中の全ての内部状態\n",
    "# 二つ目の返り値は、最後の内部状態\n",
    "# outの最後の要素とhiddenは一緒\n",
    "# outはシーケンス中の全ての内部状態を確認できる\n",
    "# hiddenは後のLSTMで引数として与えることで、シーケンスを続けたり逆伝搬をしたりするためのもの\n",
    "# ミニバッチに相当する第2次元を追加する\n",
    "inputs=torch.cat(inputs).view(len(inputs),1,-1) # 入力\n",
    "hidden=(torch.randn(1,1,3),torch.randn(1,1,3)) # 内部状態\n",
    "\n",
    "print(\"hidden before running = \",hidden)\n",
    "\n",
    "out,hidden=lstm(inputs,hidden) # LSTM\n",
    "\n",
    "print(\"out = \",out)\n",
    "print(\"hidden after running = \",hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "speech tagを取得するためにLSTMを使います。ここではViterbiやForward-Backwardのようなものは使いません。  \n",
    "まずはデータを用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:30:32.811511Z",
     "start_time": "2020-04-27T06:30:32.806808Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq,to_ix): # シーケンスを用意する関数\n",
    "    idxs=[to_ix[w] for w in seq]\n",
    "    \n",
    "    return torch.tensor(idxs,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:38:53.889815Z",
     "start_time": "2020-04-27T06:38:53.883043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "# 文章とタグの組み合わせ\n",
    "training_data=[\n",
    "    (\"The dog ate the apple\".split(),[\"DET\",\"NN\",\"V\",\"DET\",\"NN\"]),\n",
    "    (\"Everybody read that book\".split(),[\"NN\",\"V\",\"DET\",\"NN\"])\n",
    "]\n",
    "\n",
    "word_to_ix={} # 語彙、ワード→番号のdict\n",
    "\n",
    "for sent,tags in training_data: # 文章とタグ\n",
    "    for word in sent: # 文章中の各単語について\n",
    "        if word not in word_to_ix: # 語彙の中に含まれていないなら、新たに追加\n",
    "            word_to_ix[word]=len(word_to_ix) # ワード→番号\n",
    "        \n",
    "print(word_to_ix)\n",
    "\n",
    "tag_to_ix={\"DET\":0,\"NN\":1,\"V\":2} # 品詞→番号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:53:18.788108Z",
     "start_time": "2020-04-27T06:53:18.781742Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self,embedding_dim,hidden_dim,vocab_size,target_size):\n",
    "        super(LSTMTagger,self).__init__()\n",
    "        self.hidden_dim=hidden_dim # 隠れ層の次元\n",
    "        self.word_embeddings=nn.Embedding(vocab_size,embedding_dim) # 埋め込み層の次元\n",
    "        \n",
    "        # LSTMはword embeddingを入力として受け取り、内部状態hiddenとその次元hidden_dimを出力する\n",
    "        self.lstm=nn.LSTM(embedding_dim,hidden_dim)\n",
    "        \n",
    "        # 隠れ層から出力の次元までのマッピング\n",
    "        self.hidden2tag=nn.Linear(hidden_dim,target_size)\n",
    "        \n",
    "    def forward(self,sentence):\n",
    "        embeds=self.word_embeddings(sentence) # 埋め込み層\n",
    "        lstm_out,_=self.lstm(embeds.view(len(sentence),1,-1)) # embeddingを入力として受け取る\n",
    "        tag_space=self.hidden2tag(lstm_out.view(len(sentence),-1)) # タグの次元に変換\n",
    "        tag_scores=F.log_softmax(tag_space,dim=1) # タグの予測値\n",
    "        \n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それではモデルを学習させ、、、る前に、スコアを見ておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:00:16.186256Z",
     "start_time": "2020-04-27T07:00:16.141726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1460, -1.1694, -0.9901],\n",
      "        [-1.1090, -1.1806, -1.0133],\n",
      "        [-1.2453, -1.0405, -1.0248],\n",
      "        [-1.1733, -1.1479, -0.9852],\n",
      "        [-1.1454, -1.2117, -0.9565]])\n"
     ]
    }
   ],
   "source": [
    "# 大体32か64次元\n",
    "# 小さくすることで、重みが訓練中にどう変化したかを見ることができる\n",
    "EMBEDDING_DIM=6 # 埋め込み層の次元\n",
    "HIDDEN_DIM=6 # 隠れ層の次元\n",
    "\n",
    "model=LSTMTagger(EMBEDDING_DIM,HIDDEN_DIM,len(word_to_ix),len(tag_to_ix)) # モデル\n",
    "loss_function=nn.NLLLoss() # ロス関数\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.1) # 最適化関数\n",
    "\n",
    "# 学習の前のスコアを見ておく\n",
    "with torch.no_grad(): # 勾配は計算しない\n",
    "    inputs=prepare_sequence(training_data[0][0],word_to_ix) # これからモデルに入力するデータを用意する\n",
    "    tag_scores=model(inputs) # モデルの出力\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に学習させてみます。その後に改めてスコアを見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:26:12.049799Z",
     "start_time": "2020-04-27T07:26:11.190592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'ate', 'the', 'apple']\n",
      "tensor([[-9.8161e-03, -5.4920e+00, -5.1764e+00],\n",
      "        [-6.7108e+00, -3.8032e-03, -5.9607e+00],\n",
      "        [-4.4137e+00, -6.2204e+00, -1.4198e-02],\n",
      "        [-1.0209e-02, -5.6630e+00, -5.0078e+00],\n",
      "        [-4.7409e+00, -9.2672e-03, -7.6145e+00]])\n",
      "tensor([0, 1, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300): # エポックを繰り返す\n",
    "    for sentence,tags in training_data: # 訓練データ中\n",
    "        # PyTorchでは勾配が蓄積されてゆくので、最初に初期化する\n",
    "        model.zero_grad() \n",
    "        \n",
    "        # ネットワークに入れるための入力を取得する\n",
    "        # ワードの番号のテンソル\n",
    "        sentence_in=prepare_sequence(sentence,word_to_ix) # 入力する文章\n",
    "        targets=prepare_sequence(tags,tag_to_ix) # ターゲット\n",
    "        \n",
    "        # 順伝搬させる\n",
    "        tag_scores=model(sentence_in) # モデルの出力\n",
    "        \n",
    "        # ロス、勾配を計算し、パラメータを更新する\n",
    "        loss=loss_function(tag_scores,targets) # ロス\n",
    "        loss.backward() # 逆伝搬させる\n",
    "        optimizer.step() # パラメータを更新する\n",
    "\n",
    "# 学習の後のスコアを見る\n",
    "with torch.no_grad():\n",
    "    inputs=prepare_sequence(training_data[0][0],word_to_ix) # 入力\n",
    "    tag_scores=model(inputs) # モデルの出力\n",
    "    \n",
    "    # 文章は\"the dog ate the apple\"\n",
    "    # i,jはそれぞれワードiのタグj\n",
    "    # 予測タグは予測スコアの最大のもの\n",
    "    print(training_data[0][0])\n",
    "    print(tag_scores)\n",
    "    print(tag_scores.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば↑では、予測クラスは[0,1,2,0,1]となります。  \n",
    "ここで{\"DET\":0,\"NN\":1,\"V\":2}です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
